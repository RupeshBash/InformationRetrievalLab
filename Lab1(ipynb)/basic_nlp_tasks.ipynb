{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1235c4",
   "metadata": {},
   "source": [
    "# Basic NLP Tasks – Tokenization, POS Tagging, and Shallow Parsing\n",
    "\n",
    "In this lab, we demonstrate some fundamental NLP tasks:\n",
    "\n",
    "1. **Tokenization** – splitting text into words.\n",
    "2. **Part-of-Speech (POS) Tagging** – labeling words with grammatical tags.\n",
    "3. **Shallow Parsing / Chunking** – extracting noun phrases, verb phrases, and prepositional phrases.\n",
    "\n",
    "We will use a sample sentence and perform these tasks step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fa3ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: ['The', 'clever', 'brown', 'fox', 'leaps', 'over', 'the', 'sleepy', 'dog', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The clever brown fox leaps over the sleepy dog.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(sentence)\n",
    "print(\"Word Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27043fd",
   "metadata": {},
   "source": [
    "## Part-of-Speech (POS) Tagging\n",
    "\n",
    "We assign grammatical tags to each token:\n",
    "\n",
    "- **DT** – Determiner  \n",
    "- **JJ** – Adjective  \n",
    "- **NN** – Noun  \n",
    "- **VBZ** – Verb (3rd person singular present)  \n",
    "- **IN** – Preposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db7d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('The', 'DT'), ('clever', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('leaps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('sleepy', 'JJ'), ('dog', 'NN'), ('.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Simple rule-based POS tagging\n",
    "pos_tags = []\n",
    "\n",
    "for token in tokens:\n",
    "    if token.lower() in ['the', 'a', 'an']:\n",
    "        pos_tags.append((token, 'DT'))\n",
    "    elif token.lower() in ['in', 'on', 'over', 'under']:\n",
    "        pos_tags.append((token, 'IN'))\n",
    "    elif token.endswith('s') or token.endswith('es'):\n",
    "        pos_tags.append((token, 'VBZ'))\n",
    "    elif token.endswith('y') or token.lower() in ['clever', 'brown', 'sleepy']:\n",
    "        pos_tags.append((token, 'JJ'))\n",
    "    else:\n",
    "        pos_tags.append((token, 'NN'))\n",
    "\n",
    "print(\"POS Tags:\", pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4275a4",
   "metadata": {},
   "source": [
    "## Shallow Parsing / Chunking\n",
    "\n",
    "We will extract:\n",
    "\n",
    "1. **Noun Phrases (NP)** – optional determiner + adjectives + noun  \n",
    "2. **Verb Phrases (VP)** – verbs optionally followed by noun phrases  \n",
    "3. **Prepositional Phrases (PP)** – preposition + noun phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391d9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Phrases: ['The clever brown fox', 'the sleepy dog', '.']\n"
     ]
    }
   ],
   "source": [
    "def extract_noun_phrases(pos_tags):\n",
    "    noun_phrases = []\n",
    "    i = 0\n",
    "    while i < len(pos_tags):\n",
    "        phrase = []\n",
    "        # Optional determiner\n",
    "        if pos_tags[i][1] == 'DT':\n",
    "            phrase.append(pos_tags[i][0])\n",
    "            i += 1\n",
    "        # Adjectives\n",
    "        while i < len(pos_tags) and pos_tags[i][1] == 'JJ':\n",
    "            phrase.append(pos_tags[i][0])\n",
    "            i += 1\n",
    "        # Noun\n",
    "        if i < len(pos_tags) and pos_tags[i][1] == 'NN':\n",
    "            phrase.append(pos_tags[i][0])\n",
    "            i += 1\n",
    "            noun_phrases.append(\" \".join(phrase))\n",
    "        else:\n",
    "            i += 1\n",
    "    return noun_phrases\n",
    "\n",
    "noun_phrases = extract_noun_phrases(pos_tags)\n",
    "print(\"Noun Phrases:\", noun_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b508d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb Phrases: ['leaps the sleepy dog']\n"
     ]
    }
   ],
   "source": [
    "def extract_verb_phrases(pos_tags):\n",
    "    verb_phrases = []\n",
    "    i = 0\n",
    "    while i < len(pos_tags):\n",
    "        if pos_tags[i][1] in ['VB', 'VBZ']:\n",
    "            vp = [pos_tags[i][0]]\n",
    "            i += 1\n",
    "            np = extract_noun_phrases(pos_tags[i:])\n",
    "            if np:\n",
    "                vp.extend(np[0].split())\n",
    "                i += len(np[0].split())\n",
    "            verb_phrases.append(\" \".join(vp))\n",
    "        else:\n",
    "            i += 1\n",
    "    return verb_phrases\n",
    "\n",
    "verb_phrases = extract_verb_phrases(pos_tags)\n",
    "print(\"Verb Phrases:\", verb_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed65bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepositional Phrases: ['over the sleepy dog']\n"
     ]
    }
   ],
   "source": [
    "def extract_prepositional_phrases(pos_tags):\n",
    "    prep_phrases = []\n",
    "    i = 0\n",
    "    while i < len(pos_tags):\n",
    "        if pos_tags[i][1] == 'IN':\n",
    "            pp = [pos_tags[i][0]]\n",
    "            i += 1\n",
    "            np = extract_noun_phrases(pos_tags[i:])\n",
    "            if np:\n",
    "                pp.extend(np[0].split())\n",
    "                i += len(np[0].split())\n",
    "            prep_phrases.append(\" \".join(pp))\n",
    "        else:\n",
    "            i += 1\n",
    "    return prep_phrases\n",
    "\n",
    "prep_phrases = extract_prepositional_phrases(pos_tags)\n",
    "print(\"Prepositional Phrases:\", prep_phrases)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
